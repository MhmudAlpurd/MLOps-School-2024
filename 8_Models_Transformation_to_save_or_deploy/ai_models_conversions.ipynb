{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 17:44:31.827059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 17:44:32.009576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 17:44:32.072633: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 17:44:32.414448: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 17:44:34.603030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images  = train_images.reshape(-1, 28, 28, 1).astype(\"float32\")/255.0\n",
    "test_images = test_images.reshape(-1, 28, 28, 1).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730988878.368402   26473 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 17:44:38.984016: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation= 'relu'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.8936 - loss: 0.3495 - val_accuracy: 0.9853 - val_loss: 0.0521\n",
      "Epoch 2/2\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0524 - val_accuracy: 0.9898 - val_loss: 0.0386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a4b191034d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=2, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras\n",
    "model.save('mnist_saved_keras.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#h5\n",
    "model.save('mnist_saved_h5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpal59ctlr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpal59ctlr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpal59ctlr'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  134463014598608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134463014598032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134463014599568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134463014600336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134463014599184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134463014600144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134463014598416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134463014598992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1730988903.873155   26473 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1730988903.873179   26473 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-11-07 17:45:03.873702: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpal59ctlr\n",
      "2024-11-07 17:45:03.874143: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-11-07 17:45:03.874154: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpal59ctlr\n",
      "2024-11-07 17:45:03.877550: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-11-07 17:45:03.878228: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-11-07 17:45:03.901140: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpal59ctlr\n",
      "2024-11-07 17:45:03.909356: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 35656 microseconds.\n",
      "2024-11-07 17:45:03.958159: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "#tflite\n",
    "#Converter : Quantization (changing weights types : float32-->float16) + Prunning (removing not important connections) \n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open('mnist_saved_tflite.tflite', \"wb\") as f :\n",
    "    f.write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730988904.337707   26473 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730988904.342028   26473 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-11-07 17:45:04.342099: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "I0000 00:00:1730988904.342420   26473 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 17:45:04.344276: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "I0000 00:00:1730988904.526233   26473 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730988904.527242   26473 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-11-07 17:45:04.527305: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "I0000 00:00:1730988904.527563   26473 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 17:45:04.528423: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "#ONNX\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "model.output_names = ['output']\n",
    "\n",
    "\n",
    "spec =(tf.TensorSpec((None, 28, 28, 1), tf.float32, name='input'), )\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec)\n",
    "onnx.save_model(onnx_model, 'mnist_saved_onnx.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of output models\n",
    "import os\n",
    "\n",
    "\n",
    "def get_file_size(file_name, file_path):\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    file_size = file_size / (1024 * 1024)\n",
    "    print(f\"{file_name} size: {file_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 format size: 1.43 MB\n",
      "keras format size: 1.43 MB\n",
      "onnx format size: 0.47 MB\n",
      "tflite format size: 0.47 MB\n"
     ]
    }
   ],
   "source": [
    "get_file_size('h5 format', 'mnist_saved_h5.h5')\n",
    "get_file_size('keras format', 'mnist_saved_keras.keras')\n",
    "get_file_size('onnx format', 'mnist_saved_onnx.onnx')\n",
    "get_file_size('tflite format', 'mnist_saved_tflite.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "predictied_class:  3\n",
      "h5_inference_time 0.09107685089111328\n",
      "FPS (frames per second):  10.979738432058303\n"
     ]
    }
   ],
   "source": [
    "#inference_time : h5\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('mnist_saved_h5.h5')\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((28, 28))\n",
    "\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "\n",
    "    img_array = img_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "    return img_array\n",
    "\n",
    "image_path = 'three.jpg'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_image = preprocess_image(image_path)\n",
    "\n",
    "predictions = model.predict(test_image)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "h5_inference_time = end_time - start_time\n",
    "\n",
    "print( 'predictied_class: ', predicted_class[0])\n",
    "print(\"h5_inference_time\", h5_inference_time)\n",
    "\n",
    "print('FPS (frames per second): ', 1/h5_inference_time ) #---> almost realtime.(realtime > 10 FPS)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_class:  3\n",
      "tflite_inference_time 0.0020296573638916016\n",
      "FPS (frames per second):  492.69399741571715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "#tflite inference time\n",
    "\n",
    "tflite_model_path = 'mnist_saved_tflite.tflite'\n",
    "\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "image_path = 'three.jpg'\n",
    "\n",
    "\n",
    "test_image = preprocess_image(image_path)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "tflite_inference_time = end_time - start_time\n",
    "\n",
    "print( 'predicted_class: ', predicted_class[0])\n",
    "print(\"tflite_inference_time\", tflite_inference_time)\n",
    "print('FPS (frames per second): ', 1/tflite_inference_time )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_class:  3\n",
      "onnx_inference_time 0.00586247444152832\n",
      "FPS (frames per second):  170.57643661799992\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnx_model_path = 'mnist_saved_onnx.onnx'\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "\n",
    "#input_shape = onnx_model.graph.input[0].type.tensor_type.shape.dim\n",
    "#print(input_shape)\n",
    "\n",
    "\n",
    "session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "\n",
    "img = 'three.jpg'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_image = preprocess_image(img)\n",
    "\n",
    "predictions = session.run([output_name], {input_name : test_image})\n",
    "\n",
    "end_time = time.time()\n",
    "predicted_class = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "onnx_inference_time = end_time - start_time\n",
    "\n",
    "print( 'predicted_class: ', predicted_class[0])\n",
    "print(\"onnx_inference_time\", onnx_inference_time)\n",
    "print('FPS (frames per second): ', 1/onnx_inference_time )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5_inference_time 0.09107685089111328 seconds\n",
      "onnx_inference_time 0.00586247444152832 seconds\n",
      "tflite_inference_time 0.0020296573638916016 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"h5_inference_time\", h5_inference_time, 'seconds')\n",
    "print(\"onnx_inference_time\", onnx_inference_time, 'seconds')\n",
    "print(\"tflite_inference_time\", tflite_inference_time , 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "h5_accuracy:  0.9895\n",
      "tflite_accuracy:  0.9895\n",
      "onnx_accuracy:  0.9895\n"
     ]
    }
   ],
   "source": [
    "#Accuracy  --> onnx , h5 and tflite on mnist test set. \n",
    "\n",
    "import numpy as np\n",
    "import onnx \n",
    "import onnxruntime as ort\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "\n",
    "#print(x_test.shape)\n",
    "\n",
    "\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "#print(x_test.shape)\n",
    "\n",
    "\n",
    "#evaluating h5\n",
    "def evaluate_h5(h5_model_path, images):\n",
    "    model = load_model(h5_model_path)\n",
    "    y_pred = model.predict(images)\n",
    "    return np.argmax(y_pred, axis=-1)\n",
    "\n",
    "h5_model_path = 'mnist_saved_h5.h5'\n",
    "h5_predictions = evaluate_h5(h5_model_path, x_test)\n",
    "h5_accuracy = np.mean(h5_predictions==y_test)\n",
    "print('h5_accuracy: ', h5_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#evaluating tflite\n",
    "def evaluate_tflite(tflite_model_path):\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        interpreter.set_tensor(input_details[0]['index'], x_test[i:i+1])\n",
    "        interpreter.invoke()\n",
    "        predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "        y_pred.append(np.argmax(predictions))\n",
    "\n",
    "\n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "tflite_model_path = 'mnist_saved_tflite.tflite'\n",
    "tflite_predictions = evaluate_tflite(tflite_model_path)\n",
    "tflite_accuracy = np.mean(tflite_predictions==y_test)\n",
    "\n",
    "print('tflite_accuracy: ', tflite_accuracy)\n",
    "\n",
    "\n",
    "#evaluating onnx\n",
    "def evaluate_onnx(onnx_model_path):\n",
    "    session = ort.InferenceSession(onnx_model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        input_data = x_test[i:i+1].astype(np.float32)\n",
    "        predictions = session.run([output_name], {input_name : input_data})\n",
    "        y_pred.append(np.argmax(predictions[0], axis=-1))\n",
    "    return np.array(y_pred).flatten()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "onnx_model_path = 'mnist_saved_onnx.onnx'\n",
    "onnx_predictions = evaluate_onnx(onnx_model_path)\n",
    "onnx_accuracy = np.mean(onnx_predictions==y_test)\n",
    "\n",
    "print('onnx_accuracy: ', onnx_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class  SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 =  nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = x.view(x.size(0), -1) #flatten\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: 0.1588895171880722\n",
      "Epoch: 2 , Loss: 0.0021344542037695646\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "\n",
    "#preprocessing, transformation\n",
    "transform  = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, ), (0.5, )) \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterian = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterian(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch+1} , Loss: {loss.item()}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 µs, sys: 2 µs, total: 52 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "#saving pt, pth, onnx\n",
    "\n",
    "#pt\n",
    "torch.save(model, 'mnist_model_pytorch.pt') #architecture, weights\n",
    "\n",
    "\n",
    "#pth\n",
    "torch.save(model.state_dict(), 'mnist_model_pytorch.pth') #weights\n",
    "\n",
    "#onnx\n",
    "onnx_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "torch.onnx.export(model, onnx_input, 'mnist_model_pytorch.onnx', input_names=['input'], output_names=['output'])\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_pt_size :  size: 1.61 MB\n",
      "mnist_pth_size :  size: 1.61 MB\n",
      "mnist_onnx_size :  size: 1.61 MB\n",
      "h5 format size: 1.43 MB\n",
      "keras format size: 1.43 MB\n",
      "onnx format size: 0.47 MB\n",
      "tflite format size: 0.47 MB\n"
     ]
    }
   ],
   "source": [
    "get_file_size('mnist_pt_size : ', 'mnist_model_pytorch.pt')\n",
    "get_file_size('mnist_pth_size : ', 'mnist_model_pytorch.pth')\n",
    "get_file_size('mnist_onnx_size : ', 'mnist_model_pytorch.onnx')\n",
    "get_file_size('h5 format', 'mnist_saved_h5.h5')\n",
    "get_file_size('keras format', 'mnist_saved_keras.keras')\n",
    "get_file_size('onnx format', 'mnist_saved_onnx.onnx')\n",
    "get_file_size('tflite format', 'mnist_saved_tflite.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt predicted class:  3\n",
      "pt inference time:  0.013625621795654297\n",
      "CPU times: user 41 µs, sys: 2 µs, total: 43 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26473/2595358701.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('mnist_model_pytorch.pt')\n"
     ]
    }
   ],
   "source": [
    "#pt inferece\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = torch.load('mnist_model_pytorch.pt')\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def load_and_preprocess(image_path):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((28, 28)), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, ), (0.5, ))\n",
    "    ])\n",
    "    image_tensor = preprocess(image)\n",
    "    return image_tensor.unsqueeze(0)\n",
    "\n",
    "\n",
    "image_path = 'three.jpg'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "input_image  = load_and_preprocess(image_path).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "end_time = time.time()\n",
    "pt_inference_time = end_time - start_time\n",
    "\n",
    "print('pt predicted class: ', predicted_class)\n",
    "print('pt inference time: ', pt_inference_time)\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pth predicted class : 3\n",
      "pth inference time:  0.027863264083862305\n",
      "CPU times: user 26 µs, sys: 2 µs, total: 28 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26473/3435904106.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "#pth inference\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image \n",
    "\n",
    "class  SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 =  nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = x.view(x.size(0), -1) #flatten\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x \n",
    "    \n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = image.resize((28, 28))\n",
    "\n",
    "    transform  = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, ), (0.5, )) \n",
    "    ]\n",
    "    )\n",
    "\n",
    "    image = transform(image)\n",
    "\n",
    "    return image.unsqueeze(0)\n",
    "\n",
    "def predict_pth_model(model_path, image_tensor):\n",
    "    model= SimpleCNN()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return predicted.item()\n",
    "\n",
    "pth_model_path = 'mnist_model_pytorch.pth'\n",
    "image_path = 'three.jpg'\n",
    "\n",
    "\n",
    "start_time  = time.time()\n",
    "image_tensor = load_image(image_path)\n",
    "predicted_class = predict_pth_model(pth_model_path, image_tensor)\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "pth_inference_time = end_time - start_time\n",
    "\n",
    "print('pth predicted class :', predicted_class)\n",
    "print('pth inference time: ', pth_inference_time)\n",
    "\n",
    "\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26473/1220161024.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt model accuracy:  0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26473/1220161024.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pth model accuracy:  0.988\n"
     ]
    }
   ],
   "source": [
    "#pt , pth evaluation ---> finding performance metrics values. \n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image \n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "\n",
    "transform  = transforms.Compose(\n",
    "[\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, ), (0.5, )) \n",
    "]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class  SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 =  nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = x.view(x.size(0), -1) #flatten\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x \n",
    "    \n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = image.resize((28, 28))\n",
    "\n",
    "    transform  = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, ), (0.5, )) \n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_pytorch_model(model_path, model_format):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if model_format=='pth':\n",
    "        model = SimpleCNN()\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    elif model_format=='pt':\n",
    "        model = torch.load(model_path, map_location=device)\n",
    "\n",
    "    else:\n",
    "        print(' input format is not defined!')\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'{model_format} model accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "evaluate_pytorch_model('mnist_model_pytorch.pt', 'pt')\n",
    "evaluate_pytorch_model('mnist_model_pytorch.pth', 'pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx_accuracy:  0.9625\n"
     ]
    }
   ],
   "source": [
    "#pytorch onnx inference\n",
    "#Accuracy  --> onnx , h5 and tflite on mnist test set. \n",
    "\n",
    "import numpy as np\n",
    "import onnx \n",
    "import onnxruntime as ort\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "\n",
    "#print(x_test.shape)\n",
    "\n",
    "\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "#print(x_test.shape)\n",
    "\n",
    "\n",
    "#onnx input : 1, 1, 28, 28\n",
    "\n",
    "\n",
    "#evaluating onnx\n",
    "def evaluate_onnx(onnx_model_path, test_data):\n",
    "    session = ort.InferenceSession(onnx_model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    x_test = np.transpose(test_data, (0, 3, 1, 2)) #batch, channel, height, width\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        input_data = x_test[i:i+1].astype(np.float32)\n",
    "        predictions = session.run([output_name], {input_name : input_data})\n",
    "        y_pred.append(np.argmax(predictions[0], axis=-1))\n",
    "    return np.array(y_pred).flatten()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "onnx_model_path = 'mnist_model_pytorch.onnx'\n",
    "onnx_predictions = evaluate_onnx(onnx_model_path, x_test)\n",
    "onnx_accuracy = np.mean(onnx_predictions==y_test)\n",
    "\n",
    "print('onnx_accuracy: ', onnx_accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26473/1220161024.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt model accuracy:  0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26473/1220161024.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pth model accuracy:  0.988\n",
      "onnx_accuracy:  0.9625\n"
     ]
    }
   ],
   "source": [
    "evaluate_pytorch_model('mnist_model_pytorch.pt', 'pt')\n",
    "evaluate_pytorch_model('mnist_model_pytorch.pth', 'pth')\n",
    "\n",
    "print('onnx_accuracy: ', onnx_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TENSORRT --> .engine! (will be teach in the next make up session!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test = np.transpose(test_data, (0, 3, 1, 2))  #ijkl  ---> iljk ===> 2471--> 2147"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
